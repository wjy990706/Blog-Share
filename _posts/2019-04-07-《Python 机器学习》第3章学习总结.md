

---
layout:     post
title:      "《Python 机器学习》第3章学习总结"
date:       2019-04-31
author:     "董国珍"
header-img: "/Blog-share/img/post-bg-2015.jpg"
tags:
    - 数据分析
---




#  <center>《Python 机器学习》第3章学习总结<center>  

##  <center>本书简介<center>


在学习和研究机器学习的时候，面临令人眼花缭乱的算法，机器学习新手往往会不知所措。本书从算法和Python 语言实现的角度，帮助读者认识机器学习。本书专注于两类核心的“算法族”，即惩罚线性回归和集成方法，并通过代码实例来展示所讨论的算法的使用原则。全书共分为7 章，详细讨论了预测模型的两类核心算法、预测模型的构建、惩罚线性回归和集成方法的具体应用和实现。  
   
   

<img src="/Blog-share/img/1903/04/Mialia/book.png" width="500" hegiht="900" align=center />  
   
 

## 第三章 预测模型的构建
  

### 平衡性能、复杂性以及大数据  

本章讨论影响机器学习模型效果的因素，并且给出了针对不同类型问题的性能定义，描述针对不同问题的相关性能指标。


* 3.1 基本问题：理解函数逼近
  
> 训练集包括：1.要预测的结果 2.用于预测的特征  
>   
> 预测因子（特征）集合的表示符号:(X中的数据类型可能不完全相同，排列后可用一个列向量表示) 
>  
> ![avatar](/Blog-share/img/1903/04/Mialia/3.1.png)  
>  
> 评估预测模型的性能：  
> >  
> > 回归问题常用MSE（均方误差）和MAE（平均绝对误差）度量  
> >  
> > 分类问题需要使用不同的性能指标，如：误分类率
> >  

* 3.2 影响算法选择及性能的因素——复杂度以及数据
  
（包括问题的复杂度和模型的复杂度）  
  
> 对模型进行评估的最佳经验是从训练数据集中预留部分数据。
>  
> 样本外误差：将预留数据和模型生成的预测数据对比产生的结果  
> * 问题的复杂度
> > 集成方法比线性方法可以产生更多的复杂模型
> > 复杂问题需要大量数据，数据的分布形状也很重要
> * 模型的复杂度
> > 
> > 有时，线性模型相对于复杂的集成方法可能产生相同的或者更好的性能
> > 
  
* 3.3 度量预测模型性能
  
> 对预测模型进行度量的两个方面：  
>  
> 1.评价指标(对性能优化也很重要)  
>  
> 2.在预留样本上估计错误的技术
>   
>  * 不同类型问题的性能评价指标：
>   
> 1. 回归问题：  
> > MSE,MAE,RSME（MSE的平方根，可用性更好）  
> >  
> > 查看错误的分布直方图、长尾分布（使用分位数或者等分边界）、正态分布程度  
>  
> 2. 分类问题：(围绕误分类率)
> > 混淆矩阵、列联表安排可能结果的输出
> > ![avatar](/Blog-share/img/1903/04/Mialia/3.2.png)  
> >  
> > （混淆矩阵样例）
> >  
> > 决策阈值对误分类率有影响（最佳决策阈值应该是能最小化误分类率的值）  
> > 不同决策阈值有不同的错误代价  
> > 接收者操作曲线（ROC）<真正率和假正率>  
> > 曲线下的面积值（AUC）  
>  
> 一般测试集可以占所有数据的 25% ～ 35%(无明确规定，但要记住模型训练的性能随着训练集规模的减小而下降)  
> 另有预留数据的方法如：n折交叉验证（直到数据分出的块全部被预留测试一次）  
>  
> ![avatar](/Blog-share/img/1903/04/Mialia/3.3.png)  
>  
> n折交叉验证可以估计预测错误：在多份样本上估计错误来估计错误边界（时间可能过长，过长时可以使用预留测试集）  
> 注意：要使测试样本能代替整个数据集（注意抽样过程）  
  
* 3.4 模型与数据的均衡
  
(引入前向逐步回归和岭回归来调整普通最小二乘法的瓶颈)
  
> * 前向逐步回归：  
> > 最佳子集选择:去掉多少列以及哪几列应该去掉的问题(蛮力的方法)    
> > 复杂度参数:解决方案中引入的属性个数(复杂度更高的模型会有更多自由参数，相对于低复杂度的模型更容易对数据产生过拟合)  
> * 岭回归(通过惩罚回归系数来控制过拟合)

